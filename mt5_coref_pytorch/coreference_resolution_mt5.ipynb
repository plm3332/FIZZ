{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674817b8",
   "metadata": {},
   "source": [
    "# [Coreference Resolution through a seq2seq Transition-Based System](https://arxiv.org/abs/2211.12142)\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "@misc{bohnet2022coreference,\n",
    "      title={Coreference Resolution through a seq2seq Transition-Based System}, \n",
    "      author={Bernd Bohnet and Chris Alberti and Michael Collins},\n",
    "      year={2022},\n",
    "      eprint={2211.12142},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948257a4",
   "metadata": {},
   "source": [
    "Adapted from the notebook:\n",
    "https://github.com/google-research/google-research/tree/master/coref_mt5#coreference-resolution-through-a-seq2seq-transition-based-system\n",
    "\n",
    "Adapted from the github:\n",
    "https://github.com/ianporada/mt5_coref_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0b146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from datasets import Dataset\n",
    "from transformers import MT5Tokenizer, T5ForConditionalGeneration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744e4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import State\n",
    "from util import (create_document, create_next_batch, extract_result_string,\n",
    "                  predict_coreferences, read_jsonl, write_jsonl)\n",
    "from typing import List\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9f8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d80977",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b77553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plm3332/.conda/envs/torch_ex/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/aggre_fact_final.csv\"\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "dataset_final = Dataset.from_pandas(df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52941848",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33f141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48faad356064c12b044be3c291cf53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plm3332/.conda/envs/torch_ex/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer_nltk = nltk.WordPunctTokenizer()\n",
    "model_ckpt = \"mt5-coref-pytorch/link-append-xxl\"\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_ckpt, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_ckpt, \n",
    "                                                   torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecd4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpand_only = False\n",
    "\n",
    "pronouns = [\"i\", \"he\", \"she\", \"you\", \"me\", \"him\", \"myself\", \"yourself\", \"himself\", \"herself\", \"yourselves\"]\n",
    "special_pronouns = [\"my\", \"mine\", \"her\", \"hers\", \"his\", \"your\", \"yours\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be36db",
   "metadata": {},
   "source": [
    "## Extract Coreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778bfaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "france ' s dubuisson carded a 67 to tie with overnight leader van zyl of south africa on 16 under par . [1 mcilroy ] carded a third straight five under - par 67 to move to 15 under par with thailand ' s kiradech aphibarnrat . [1 the world number three ' s ] round included an eagle on the 12th as [1 he ] bids to win [1 his ] first title since may . \" the 67s [1 i ] ' ve shot this week have all been a little different and [1 i ] feel like [1 i ] ' ve played within [1 myself ] for all of them , \" said [1 four - time major winner mcilroy of northern ireland ] . \" [1 i ] feel there ' s a low round out there for [1 me ] and hopefully it ' s tomorrow .\" [1 mcilroy ] was level par for the day after 10 holes , dropping [1 his ] first shots of the week by three - putting the third and 10th , the latter mistake prompting [1 the 26 - year - old ] to throw [1 his ] putter at [1 his ] bag . but [1 he ] hit back with a birdie on the par - five 11th and a towering four iron from 229 yards on the 13th set up an eagle from just four feet . [1 the former world number one ] ruptured a ligament in [1 his ] left ankle during a game of football with friends in july , ruling [1 him ] out of several tournaments . but [1 he ] returned in time to unsuccessfully defend [1 his ] us pga title at whistling straits in august and played in three of the fedex cup play - off events before starting the new pga tour season with a tie for 26th in the frys . com open in california . [1 he ] is targeting a third race to dubai title in four years and leads england ' s danny willett by 271 , 214 points with three events remaining after the turkish open . english pair chris wood (- 13 ) and richard bland (- 12 ) who were tied for second overnight are fifth and seventh respectively .\n",
      "\n",
      "france ' s dubuisson carded a 67 to tie with overnight leader van zyl of south africa on 16 under par . mcilroy carded a third straight five under - par 67 to move to 15 under par with thailand ' s kiradech aphibarnrat . Mcilroy, the world number three ' s round included an eagle on the 12th as Mcilroy bids to win Mcilroy's first title since may . \" the 67s Mcilroy ' ve shot this week have all been a little different and Mcilroy feel like Mcilroy ' ve played within Mcilroy for all of them , \" said Mcilroy, four - time major winner mcilroy of northern ireland . \" Mcilroy feel there ' s a low round out there for Mcilroy and hopefully it ' s tomorrow .\" mcilroy was level par for the day after 10 holes , dropping Mcilroy's first shots of the week by three - putting the third and 10th , the latter mistake prompting Mcilroy, the 26 - year - old to throw Mcilroy's putter at Mcilroy's bag . but Mcilroy hit back with a birdie on the par - five 11th and a towering four iron from 229 yards on the 13th set up an eagle from just four feet . Mcilroy, the former world number one ruptured a ligament in Mcilroy's left ankle during a game of football with friends in july , ruling Mcilroy out of several tournaments . but Mcilroy returned in time to unsuccessfully defend Mcilroy's us pga title at whistling straits in august and played in three of the fedex cup play - off events before starting the new pga tour season with a tie for 26th in the frys . com open in california . Mcilroy is targeting a third race to dubai title in four years and leads england ' s danny willett by 271 , 214 points with three events remaining after the turkish open . english pair chris wood (- 13 ) and richard bland (- 12 ) who were tied for second overnight are fifth and seventh respectively .\n"
     ]
    }
   ],
   "source": [
    "doc = dataset_final['doc'][0].title()\n",
    "\n",
    "\"\"\"\n",
    "Adapted from the github:\n",
    "https://github.com/ianporada/mt5_coref_pytorch\n",
    "\"\"\"\n",
    "inputs = [{'document_id': 'example_doc', 'sentences':[]}]\n",
    "sentences_list = sent_tokenize(doc)\n",
    "for sentence in sentences_list:\n",
    "    d = {'speaker': '_', 'words': tokenizer_nltk.tokenize(sentence)}\n",
    "    inputs[0]['sentences'].append(d)\n",
    "\n",
    "states_dict = {}\n",
    "for doc in inputs:\n",
    "    states_dict[doc['document_id']] = State(create_document(doc), tokenizer)\n",
    "\n",
    "num_done = 0\n",
    "while num_done < len(states_dict):  # while states\n",
    "    states, batches = create_next_batch(states_dict)\n",
    "\n",
    "    if not states:\n",
    "        break\n",
    "\n",
    "    documents_processing = set([x.input_document['doc_key'] for x in states])\n",
    "\n",
    "    predictions = predict_coreferences(tokenizer, model, batches, len(batches))\n",
    "    results = extract_result_string(predictions)\n",
    "\n",
    "    for state, result, batch in zip(states, results, batches):\n",
    "        state.extend(result)\n",
    "\n",
    "\"\"\"\n",
    "Adapted from the notebook:\n",
    "https://github.com/google-research/google-research/tree/master/coref_mt5#coreference-resolution-through-a-seq2seq-transition-based-system\n",
    "\"\"\"\n",
    "for doc_name, s in states_dict.items():\n",
    "    all_pred_clusters = [cluster for name, cluster in s.cluster_name_to_cluster.items()]\n",
    "\n",
    "    text, text_map = [], []\n",
    "    for k, snt in states_dict[doc_name].input_document['sentences'].items():\n",
    "        m = states_dict[doc_name].input_document['token_maps'][k]\n",
    "        text += snt\n",
    "        text_map += m\n",
    "\n",
    "    # custom\n",
    "    words_dict = {}\n",
    "    pred_clusters = []\n",
    "    for pred_cluster in all_pred_clusters:\n",
    "        person_flag = False\n",
    "        for st, en in pred_cluster:\n",
    "            head = \" \".join(text[st:en+1]).title()\n",
    "            head_nlp = nlp(head)\n",
    "            if len(head_nlp.ents) >= 3:   #unnecessary\n",
    "                continue\n",
    "            for ent in head_nlp.ents:\n",
    "                if ent.label_ == \"PERSON\":\n",
    "                    person_entity_index = s.mention_index_to_cluster_name[str(tuple([st, en]))]\n",
    "                    if person_entity_index not in words_dict.keys():\n",
    "                        ent_text = ent.text\n",
    "                        if \"'s\" in ent_text:\n",
    "                            ent_text = ent_text.replace(\"'s\", '')\n",
    "                        elif \" ' s\" in ent_text:\n",
    "                            ent_text = ent_text.replace(\" ' s\", '')\n",
    "                        elif \"' s\" in ent_text:\n",
    "                            ent_text = ent_text.replace(\"' s\", '')\n",
    "                        words_dict[person_entity_index] = ent_text\n",
    "                    person_flag=True\n",
    "                    break\n",
    "        if person_flag:\n",
    "            pred_clusters.append(pred_cluster)\n",
    "\n",
    "    cluster_annotations_start = []\n",
    "    cluster_annotations_end = []\n",
    "\n",
    "    for tid in text_map:\n",
    "        cluster_annotations_start.append([])\n",
    "        cluster_annotations_end.append([])\n",
    "        for ci in pred_clusters:\n",
    "            for m in ci:\n",
    "                if tid == m[0]:\n",
    "                    m_len = m[1] - m[0]\n",
    "                    name = s.mention_index_to_cluster_name[str(m)]\n",
    "                    cluster_annotations_start[-1].append((name, m_len))\n",
    "\n",
    "                if tid == m[1]:\n",
    "                    cluster_annotations_end[-1].append(']')\n",
    "\n",
    "    all_text = []\n",
    "    resolved_text = []\n",
    "\n",
    "    for tok, start, end in zip(text, cluster_annotations_start, cluster_annotations_end):\n",
    "        is_resolved = False\n",
    "        if start:\n",
    "            for x in [start[0]]:\n",
    "                lower_tok = tok.lower()\n",
    "                if lower_tok in pronouns:\n",
    "                    try:\n",
    "                        resolved_text.append(words_dict[x[0]])\n",
    "                        is_resolved = True\n",
    "                    except:\n",
    "                        continue\n",
    "                elif lower_tok in special_pronouns:\n",
    "                    try:\n",
    "                        resolved_text.append(words_dict[x[0]] + \"'s\")\n",
    "                        is_resolved = True\n",
    "                    except:\n",
    "                        continue\n",
    "                else:\n",
    "                    tok_nlp = nlp(tok)\n",
    "                    if tok_nlp.text == \"ms\" or tok_nlp.text == \"mr\":\n",
    "                        break\n",
    "                    for ent in tok_nlp.ents:\n",
    "                        if ent.label_ == \"PERSON\" or ent.label_ == \"ORG\":\n",
    "                            break\n",
    "                    else:\n",
    "                        try:\n",
    "                            resolved_text.append(words_dict[x[0]] + ',')\n",
    "                        except:\n",
    "                            continue\n",
    "        if not is_resolved:\n",
    "            resolved_text.append(tok.lower())\n",
    "\n",
    "    for tok, start, end in zip(text, cluster_annotations_start, cluster_annotations_end):\n",
    "        if start:\n",
    "            for x in sorted(start, key=lambda x : x[1], reverse=True):\n",
    "                all_text.append('['+str(x[0]))\n",
    "\n",
    "        all_text.append(tok.lower())\n",
    "\n",
    "        if end:\n",
    "            all_text.append(''.join(end))\n",
    "\n",
    "    print()\n",
    "    print(' '.join(all_text))\n",
    "    print()\n",
    "    print(' '.join(resolved_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80d263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ex",
   "language": "python",
   "name": "torch_ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
