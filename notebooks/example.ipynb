{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7164a42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02d0ef",
   "metadata": {},
   "source": [
    "## Load NLI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6e5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_ckpt = \"tals/albert-xlarge-vitaminc-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfb4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences = [sent for sent in sentences if len(sent)>10]\n",
    "    return sentences\n",
    "\n",
    "def is_consecutive_by_one(numbers):\n",
    "    for i in range(1, len(numbers)):\n",
    "        if abs(numbers[i] - numbers[i-1]) != 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9a0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = \"looking after elderly parents can be difficult at the best of times . but lu xincai, this man takes caring for lu xincai's alzheimer ' s - suffering mother to another level . lu xincai, a security guard from china has touched hearts across the country because lu xincai takes lu xincai's 84 - year - old mother with lu xincai to work on the back of lu xincai's motorbike every single day , reported the people ' s daily online . lu xincai, lu xincai , who lives in zhejiang province in eastern china , says that lu xincai is scared lu xincai's mother will get lost if lu xincai leaves her at home by herself because she suffers from the degenerative disease . devoted : lu xincai, lu xincai takes lu xincai's 84 - year - old mother to work with lu xincai on the back of lu xincai's motorbike every day . lu xincai ties a sash around both of their waists to make sure she does n ' t fall off she would often go up to the mountains to collect firewood and there were a few occasions when she got lost after dark . when mr lu ' s father passed away earlier this year , lu xincai decided to take lu xincai's mother with lu xincai to work because there was no one else who could look after her . lu xincai's wife works in a different city and lu xincai's son is still in school . after helping lu xincai's mother to get up at 5 am every morning , lu xincai puts her on the back seat of lu xincai's motorbike and ties a sash around both of their waists to ensure that she does not fall off . mr lu said that lu xincai rides the four kilometres to work slowly to make sure lu xincai's mother feels safe and so that they can chat along the way . the whole journey takes an hour . even when at work lu xincai checks up on lu xincai's mother , who has been given her own room by lu xincai's employers , a bank , to make sure that she has not wandered off somewhere . lu xincai said that lu xincai's mother devoted her life to caring for her children , and now lu xincai feels like lu xincai has a duty to care for her in return . vulnerable : lu xincai's elderly mother suffers from alzheimer ' s and used to get lost when she was left alone lu xincai said : ` lu xincai was an apple in lu xincai's mum ' s eye , and now she ' s lu xincai's apple . ' ` our mother carried us on her back to the fields when she went to work on the farm and collect firewood when we were young . ' lu xincai added : ` only if lu xincai see her will lu xincai feel relaxed . otherwise lu xincai would be afraid is she had wandered away . '\"\n",
    "summary_sample = \"lu xincai takes Lu Xincai's 84 - year - old mother to work with Lu Xincai on the back of Lu Xincai's motorbike every day . Lu Xincai's mother suffers from alzheimer ' s and used to get lost when she was left alone . Lu Xincai ties a sash around both of their waists to ensure that she does not fall off .\"\n",
    "atomic_facts_sample = \"Lu Xincai has a 84 - year - old mother. Lu Xincai takes his mother to work with him. Lu Xincai's mother works with him on the back of his motorbike. Lu Xincai uses a motorbike to take his mother to work. Lu Xincai has a mother. Lu Xincai's mother suffers from Alzheimer's. Lu Xincai's mother used to get lost when she was left alone. Lu Xincai ties a sash. The sash is around both of their waists. The purpose of the sash is to ensure that she does not fall off.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f8ea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9676105976104736]\n"
     ]
    }
   ],
   "source": [
    "gran = 3 + 1\n",
    "analyze_scores = []\n",
    "doc_sentences = split_sentences(doc_sample)\n",
    "# summary_sentences = split_sentences(summary_sample)\n",
    "summary_sentences = split_sentences(atomic_facts_sample)\n",
    "max_scores = []\n",
    "for j in range(len(summary_sentences)):\n",
    "    summary_sentence = summary_sentences[j].strip()\n",
    "    summary_scores = [[], [], []]\n",
    "    # doc scoring\n",
    "    for k in range(len(doc_sentences)):\n",
    "        doc_sentence = doc_sentences[k].strip()\n",
    "        features = tokenizer([doc_sentence], [summary_sentence], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(**features).logits\n",
    "            scores = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        entail_score = np.array(scores[0][0].cpu()).item()\n",
    "        cont_score = np.array(scores[0][1].cpu()).item()\n",
    "        neut_score = np.array(scores[0][2].cpu()).item()\n",
    "\n",
    "        summary_scores[0].append(entail_score)\n",
    "        summary_scores[1].append(cont_score)\n",
    "        summary_scores[2].append(neut_score)\n",
    "\n",
    "    max_entail_score = max(summary_scores[0])\n",
    "    max_entail_idx = summary_scores[0].index(max_entail_score)\n",
    "\n",
    "    # e > c and e > n\n",
    "    if summary_scores[0][max_entail_idx] > summary_scores[1][max_entail_idx] and summary_scores[0][max_entail_idx] > summary_scores[2][max_entail_idx]:\n",
    "        max_scores.append(max_entail_score)\n",
    "    else:\n",
    "        temp_scores = []\n",
    "        new_doc_sentences = []\n",
    "\n",
    "        expanded_gran_list = []\n",
    "        for g in range(1, gran):\n",
    "            combination = combinations(list(range(len(doc_sentences))), g)\n",
    "            comb_list = list(combination)\n",
    "            expanded_gran_list.extend(comb_list)\n",
    "\n",
    "        expanded_gran_idx_list = []\n",
    "        for expanded_gran in expanded_gran_list:\n",
    "            idx_list = list(expanded_gran)\n",
    "            if max_entail_idx in idx_list and is_consecutive_by_one(idx_list):\n",
    "                expanded_gran_idx_list.append(idx_list)\n",
    "\n",
    "        for gran_idx_list in expanded_gran_idx_list:\n",
    "            new_doc_sentence = \"\"\n",
    "            for idx in gran_idx_list:\n",
    "                new_doc_sentence += doc_sentences[idx] + \" \"\n",
    "            new_doc_sentences.append(new_doc_sentence)\n",
    "\n",
    "        for new_doc_sentence in new_doc_sentences:\n",
    "            features = tokenizer([new_doc_sentence], [summary_sentence], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(**features).logits\n",
    "                scores = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            entail_score = np.array(scores[0][0].cpu()).item()\n",
    "            temp_scores.append(entail_score)\n",
    "\n",
    "        max_temp_score = max(temp_scores)\n",
    "        max_scores.append(max(max_entail_score, max_temp_score))\n",
    "analyze_scores.append(min(max_scores))\n",
    "print(analyze_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ex",
   "language": "python",
   "name": "torch_ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
